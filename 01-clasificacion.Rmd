---
title: "01 - Clasificacion"
author: "Miguel Ángel Porras Naranjo"
date: "20 de febrero de 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Problema de clasificación

## Pasos previos

Para empezar, importamos nuestro archivo de datos `datawork.csv`.

```{r,  echo=FALSE}
library(readr)
df <- read_delim("datawork.csv", ";", escape_double = FALSE, trim_ws = TRUE)
```

Veamos una breve descripción del conjunto de datos.

```{r}
head(df)
```

```{r}
summary(df)
```

Observamos que la primera columna la interpreta como un string. Transformemos esta columna a factores.

```{r}
df$clasobj <- as.factor(df$clasobj)
```

Comprobamos que ha leido bien los datos.

```{r}
summary(df)
```

Por último veamos cuantos datos tenemos.

```{r}
dim(df)
```

## Conjunto Test y Train

Fijamos una semilla para trabajar.

```{r}
set.seed(2017)
```

Seleccionamos los datos, los normalizamos, y los guardamos en las variables `df.train` y `df.test`.

```{r}
library(rknn)
n <- dim(df)[1]
val <- sample(1:n, size = round(n/3), replace = FALSE, prob = rep(1/n, n))

df.train <- data.frame(clasobj=df$clasobj[-val], varobj=df$varobj[-val], normalize.unit(df[-val,c(-1,-2)]))
df.test <- data.frame(clasobj=df$clasobj[val], varobj=df$varobj[val], normalize.unit(df[val,c(-1,-2)]))
```



## KNN ponderado con validación cruzada.

Usamos la función `train.kknn` de la librería `kknn`.

```{r}
library(kknn)
(fit.train1 <- train.kknn(clasobj ~ ., df.train[,-2], kmax = 20,
                          kernel = c("triangular", "rectangular", "epanechnikov", "optimal",
                                     "gaussian", "rank","inv"),  
                          distance = 2))
```

Nos dice que el mejor kernel es el rectangular con `k` igual a 4.

```{r}
fit.train1$best.parameters 
fit.train1$response      
```

Veamos una representación de los kernels respecto los `k`.

```{r}
plot(fit.train1)
```

## Clasificiación del conjunto test.

Las predicciones para `df.test` son las siguientes.

```{r}
(df.pred1 <-predict(fit.train1, df.test[,-2]))
```

Veamos como de bueno es el modelo con la matriz de confusión.

```{r}
(table.conf <- table(df.pred1, df.test$clasobj))
```

La tasa de error para el conjunto test es,

```{r}
(table.conf[1,2] + table.conf[1,3] + table.conf[1,4] + table.conf[2,1] + table.conf[2,3] + table.conf[2,4] + table.conf[3,1] + table.conf[3,2] + table.conf[3,4] + table.conf[4,1] + table.conf[4,2] + table.conf[4,3]) / dim(df.test)[1]
```

Observamos que la proporción de error es muy pequeña.

El error de clasificación para el caso óptimo es,

```{r}
fit.train1$MISCLASS[fit.train1$best.parameters$k,fit.train1$best.parameters$kernel]
```













